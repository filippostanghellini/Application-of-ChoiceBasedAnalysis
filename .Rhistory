library(ggplot2)
library(reshape2)
cor_mat <- cov2cor(cov.mlogit(m2.mixed2))
cor_long <- melt(cor_mat)
ggplot(cor_long, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1, 1)) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "", y = "", fill = "Correlation")
# We can also obtain the standard errors of the correlations among random effects,
# and hence perform significance test
summary(vcov(m2.mixed2, what = "rpar", type = "cor"))
# We may restrict the correlation to only random parameters with significant association
m2.mixed3 <- update(m2.mixed2, correlation = c("cost20", "cost25"))
# The significant presence of random coefficients and their correlation
# can be further investigated using the ML tests, such as the ML ratio test
lrtest(m2, m2.mixed) #Fixed effects vs. uncorrelated random effects
lrtest(m2.mixed, m2.mixed2) #Uncorrelated random effects vs. all correlated random effects
lrtest(m2.mixed3, m2.mixed2) #Partially correlated random effects vs. all correlated random effects
# m2.mixed2 results as the best model
# Simulating shares
# To compute share predictions with a mixed MNL model,
# we can use the "predict.mixed.mnl" function, which works in the same way as "predict.mnl",
# but with the difference that we now compute the preference shares for each of "nresp"
# newly sampled, representative respondents. The part worths for these respondents
# are drawn from a multivariate normal distribution with mean set at our estimated
# value of mu and covariance equal to our estimated value of Sigma (draws <-
# mvrnorm(n=nresp, coef.mu, coef.Sigma). The computation for each
# respondent is exactly the same as our computation in predict.mnl. Once we
# have the preference shares for all of the representative respondents, we average across respondents
# to get our overall preference share predictions.
library(MASS)
predict.mixed.mnl <- function(model, data, nresp=1000) {
# Function for predicting shares from a mixed MNL model
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
#       predict shares. Same format at the data used to estimate model.
# Note that this code assumes all model parameters are random
data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
coef.Sigma <- cov.mlogit(model)
coef.mu <- model$coef[1:dim(coef.Sigma)[1]]
draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
for (i in 1:nresp) {
utility <- data.model%*%draws[i,]
share = exp(utility)/sum(exp(utility))
shares[i,] <- share
}
cbind(colMeans(shares), data)
}
set.seed(1111)
predict.mixed.mnl(m2.mixed2, data=new.data)
predict.mixed.mnl(m2.mixed2, data=new.data_new) # prediciton with our new product
#install.packages("idefix")
#install.packages("mlogit")
#install.packages("MASS")
#install.packages("reshape2")
#install.packages("car")
################################################################
### Analysis of Choice Based Conjoint survey data            ###
### The Multinomial Logit and Mixed Multinomial Logit models ###
################################################################
# load library for fitting multinomial logit models
library(dfidx)
library(mlogit)
# import the data about the choice_data Survey for conjoint analysis
choice_data <- read.csv("data/Choice_Data_Converted.csv", sep=";")
head(choice_data)
# see some descriptive statistics
summary(choice_data)
# Compute frequency tables
tab_spec <- xtabs(choice ~ spec, data = choice_data)
tab_vel  <- xtabs(choice ~ vel,  data = choice_data)
tab_qual <- xtabs(choice ~ qual, data = choice_data)
tab_priv <- xtabs(choice ~ priv, data = choice_data)
tab_cost <- xtabs(choice ~ cost, data = choice_data)
# Set layout: 3 plots on the first row, 2 on the second
par(mfrow = c(2, 3), mar = c(4, 4, 3, 1))
# Define a single coherent blue palette
blue_palette <- c("#deebf7", "#c6dbef", "#9ecae1", "#6baed6", "#3182bd")
# Draw barplots (same palette used in each subplot)
barplot(tab_spec, main = "Choice by Specification",
col = blue_palette, border = NA)
barplot(tab_vel,  main = "Choice by Speed",
col = blue_palette, border = NA)
barplot(tab_qual, main = "Choice by Quality",
col = blue_palette, border = NA)
barplot(tab_priv, main = "Choice by Privacy",
col = blue_palette, border = NA)
barplot(tab_cost, main = "Choice by Cost",
col = blue_palette, border = NA)
# recode some variables
choice_data$spec <- factor(choice_data$spec, levels=c("Assistente","Codice","Content")) # change order of categories
choice_data$vel <- factor(choice_data$vel, levels=c("Lento","Veloce")) # change order of categories
choice_data$qual <- factor(choice_data$qual, levels=c("Sufficente","Ottimale")) # change order of categories
choice_data$priv <- factor(choice_data$priv, levels=c("Bassa","Alta")) # change order of categories
choice_data$cost <- as.factor(choice_data$cost) # convert the variable as qualitative
# Fitting a choice model with "mlogit" function
# mlogit requires the choice data to be in a special data format created using the
# dfidx() function. You pass your choice data to dfidx, along
# with a few parameters telling it how the data is organized.
# dfidx() accepts data in either a "long" or a "wide" format and you tell it
# which you have using the shape parameter.
# 1) Create ID
choice_data$choice_id <- with(choice_data, paste(resp.id, ques, sep = "_"))
# 2) dfix for choice_data
choice_data.mlogit <- dfidx(
choice_data,
idx    = list(c("choice_id", "resp.id"), "alt"),
choice = "choice",
shape  = "long"
)
# The resulting choice_data.mlogit is a "dfidx" class object that can be used to estimate
# a model with mlogit(). The syntax for mlogit uses formula notation
# similarly to other functions for regression models in R.
# However, it requires the use of symbol "|" to distinguish between alternative-specific
# and non-alternative specific variables.
m1 <- mlogit(choice ~ spec + vel + qual + priv + cost, data = choice_data.mlogit)
summary(m1)
# Fit the model without intercept parameters
m2 <- mlogit(choice ~ spec + vel + qual + priv + cost | -1, data = choice_data.mlogit)
summary(m2)
# Test the restriction on the intercepts by comparing the two models
# through a likelihood ratio test
lrtest(m2, m1)
# Fit the model without intercept parameters and with price as a quantitative variable
m3 <- mlogit(choice ~ spec + vel + qual + priv
+ as.numeric(as.character(cost)) | -1, data = choice_data.mlogit)
summary(m3)
lrtest(m3, m2)
# We use model m3
library(gridExtra)
library(ggplot2)
# Extract coefficient table from m3
summ_m3  <- summary(m3)
coef_mat <- as.data.frame(summ_m3$CoefTable,
stringsAsFactors = FALSE)
# Add attribute names as first column
coef_tab <- data.frame(
Attribute = rownames(coef_mat),
coef_mat,
row.names       = NULL,
check.names     = FALSE,
stringsAsFactors = FALSE
)
# Make sure p-values are numeric
pvals <- as.numeric(coef_tab[["Pr(>|z|)"]])
# Significance stars
coef_tab$Signif <- cut(
pvals,
breaks = c(-Inf, 0.01, 0.05, 0.10, Inf),
labels = c("***", "**", "*", "")
)
# Rounding
coef_tab$Estimate      <- round(as.numeric(coef_tab$Estimate), 3)
coef_tab$`Std. Error`  <- round(as.numeric(coef_tab$`Std. Error`), 3)
coef_tab$`z-value`     <- round(as.numeric(coef_tab$`z-value`), 3)
coef_tab$`Pr(>|z|)`    <- signif(pvals, 3)
# Column names
colnames(coef_tab) <- c("Attribute", "Estimate", "Std. Error", "z value", "Pr(>|z|)", "Signif.")
# Table as graphic
table_plot <- tableGrob(coef_tab)
grid.arrange(table_plot)
##### Compute the willingness to pay
#WTP codice
-coef(m3)["specCodice"]/(coef(m3)["as.numeric(as.character(cost))"])
#WTP content
-coef(m3)["specContent"]/(coef(m3)["as.numeric(as.character(cost))"])
#WTP veloce
-coef(m3)["velVeloce"]/(coef(m3)["as.numeric(as.character(cost))"])
#WTP quality
-coef(m3)["qualOttimale"]/(coef(m3)["as.numeric(as.character(cost))"])
#WTP privacy
-coef(m3)["privAlta"]/(coef(m3)["as.numeric(as.character(cost))"])
################################################################
################################################################
# Delta method for WTP
# It allow us to calculate standard error and CI for each WTP
library(car)
attributes <- c("specCodice", "specContent", "velVeloce", "qualOttimale", "privAlta")
wtp_table <- data.frame()
for (attr in attributes) {
formula_str <- paste0("-", attr, " / `as.numeric(as.character(cost))`")
dm <- deltaMethod(m3, formula_str)
wtp_table <- rbind(wtp_table, data.frame(
Attribute = attr,
WTP      = round(dm$Estimate, 2),
SE       = round(dm$SE, 2),
CI_Lower = round(dm$`2.5 %`, 2),
CI_Upper = round(dm$`97.5 %`, 2)
))
}
wtp_plot <- tableGrob(wtp_table)
grid.arrange(wtp_plot)
################################################################
################################################################
# Simulate preference shares using the "predict.mnl" function
# Define the function
predict.mnl <- function(model, data) {
# Function for predicting preference shares from a MNL model
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
# predict shares.  Same format at the data used to estimate model.
data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
logitUtility <- data.model%*%model$coef
share <- exp(logitUtility)/sum(exp(logitUtility))
cbind(share, data)
}
################################################################
################################################################
# In order to use "predict.mnl", you need to define a data frame containing the set of designs
# for which you want to predict the preference shares.
# One way to do this is to create the full set of possible designs
# using expand.grid() and select the designs we want by row number
attributes <- list(spec=names(table(choice_data.mlogit$spec)),
vel=names(table(choice_data.mlogit$vel)),
qual=names(table(choice_data.mlogit$qual)),
priv=names(table(choice_data.mlogit$priv)),
cost=names(table(choice_data.mlogit$cost)))
allDesign <- expand.grid(attributes)
allDesign #all possible design
# we choose a reasonable and realistic subset (where the first row indicates our design), such as
new.data <- allDesign[c(2, 32, 28, 67, 6, 69), ]
new.data
# We then pass these designs to predict.mnl() to determine what customers
# would choose if they had to pick among these six choice_data alternatives:
predict.mnl(m3, new.data) # using m3 specification
# Plot
pred <- predict.mnl(m3, new.data)
pred_table <- as.data.frame(pred, row.names = NULL)
pred_table$share <- round(pred_table$share, 4)
pred_plot <- tableGrob(pred_table)
grid.arrange(pred_plot)
# Compute and plot preference share sensitivity
# Producing a sensitivity chart using R is relatively simple: we just need to loop through all
# the attribute levels, compute a preference share prediction, and save the predicted preference share for
# the target design. The "sensitivity.mnl" function does that.
sensitivity.mnl <- function(model, attrib, base.data, competitor.data) {
# Function for creating data for a preference share-sensitivity chart
# model: mlogit object returned by mlogit() function
# attrib: list of vectors with attribute levels to be used in sensitivity
# base.data: data frame containing baseline design of target product
# competitor.data: data frame contining design of competitive set
data <- rbind(base.data, competitor.data)
base.share <- predict.mnl(model, data)[1,1]
share <- NULL
for (a in seq_along(attrib)) {
for (i in attrib[[a]]) {
data[1,] <- base.data
data[1,a] <- i
share <- c(share, predict.mnl(model, data)[1,1])
}
}
data.frame(level=unlist(attrib), share=share, increase=share-base.share)
}
base.data <- new.data[1,]
competitor.data <- new.data[-1,]
(tradeoff <- sensitivity.mnl(m2, attributes, base.data, competitor.data))
barplot(tradeoff$increase, horiz=FALSE, names.arg=tradeoff$level,
ylab="Change in Share for the Planned Product Design",
ylim=c(-0.1,0.11))
grid(nx=NA, ny=NULL)
# Colored barplot for our future implementation
cols <- rep("gray", length(tradeoff$level))
cols[tradeoff$level == "Alta"] <- "red"
par(mfrow=c(1,1))
barplot(tradeoff$increase,
horiz = FALSE,
names.arg = tradeoff$level,
ylab = "Change in Share for the Planned Product Design",
ylim = c(-0.1, 0.11),
col = cols)
grid(nx = NA, ny = NULL)
################################################################
################################################################
# we want to test our product preference share
new.data_new <- allDesign[c(14, 32, 28, 67, 6, 69), ]
new.data_new
predict.mnl(m3, new.data_new)
#Plot
pred_new <- predict.mnl(m3, new.data_new)
pred_table_new <- as.data.frame(pred_new, row.names = NULL)
pred_table_new$share <- round(pred_table_new$share, 4)
pred_plot_new <- tableGrob(pred_table_new)
grid.arrange(pred_plot_new)
# Fit a mixed MNL model
# The statistical term for coefficients that vary across respondents (or customers) is
# random coefficients or random effects. To estimate a multinomial
# logit model with random coefficients using "mlogit", we define a vector indicating
# which coefficients should vary across customers. "mlogit" requires a character
# vector the same length as the coefficient vector with a letter code indicating what
# distribution the random coefficients should follow across the respondents: "n" for
# normal, "l" for log normal, "t" for truncated normal, and "u" for uniform. For this
# analysis, we assume that all the coefficients are normally distributed across the population
# and call our vector "m2.rpar".
m2.rpar <- rep("n", length=length(m2$coef))
names(m2.rpar) <- names(m2$coef)
m2.rpar
# We pass this vector to mlogit as the rpar parameter, which is short for "random
# parameters". In addition, we tell mlogit that we have multiple choice observations
# for each respondent (panel=TRUE) and whether we want to allow the random
# parameters to be correlated with each other. For this first run, we assume that we do
# not want random parameters to be correlated (correlation=FALSE), a setting
# we reconsider below.
m2.mixed <- mlogit(choice ~ spec + vel + qual + priv + cost | -1,
data = choice_data.mlogit,
panel=TRUE, rpar = m2.rpar, correlation = FALSE)
summary(m2.mixed)
# We can get a visual summary of the distribution of random effects and hence of the level of heterogeneity
plot(m2.mixed)
summ_m2 <- summary(m2.mixed)
coef_mat <- as.data.frame(summ_m2$CoefTable, stringsAsFactors = FALSE)
coef_tab <- data.frame(Attribute = rownames(coef_mat), coef_mat, row.names = NULL, check.names = FALSE, stringsAsFactors = FALSE)
pvals <- as.numeric(coef_tab[["Pr(>|z|)"]])
coef_tab$Signif <- cut(pvals, breaks = c(-Inf, 0.01, 0.05, 0.10, Inf), labels = c("***", "**", "*", ""))
coef_tab$Estimate <- round(as.numeric(coef_tab$Estimate), 3)
coef_tab$`Std. Error` <- round(as.numeric(coef_tab$`Std. Error`), 3)
coef_tab$`z-value` <- round(as.numeric(coef_tab$`z-value`), 3)
coef_tab$`Pr(>|z|)` <- signif(pvals, 3)
colnames(coef_tab) <- c("Attribute", "Estimate", "Std. Error", "z value", "Pr(>|z|)", "Signif.")
table_plot <- tableGrob(coef_tab)
grid.arrange(table_plot)
#Tables
pred_mixed_new <- predict.mnl(m3, new.data_new)
pred_table_new <- as.data.frame(pred_mixed_new, row.names = NULL)
pred_mixed_table_new$share <- round(pred_table_new$share, 4)
#Tables
pred_mixed_new <- predict.mnl(m3, new.data_new)
pred_mixed_table_new <- as.data.frame(pred_mixed_new, row.names = NULL)
pred_mixed_table_new$share <- round(pred_mixed_table_new$share, 4)
pred_mixed_plot_new <- tableGrob(pred_mixed_table_new)
grid.arrange(pred_mixed_plot_new)
pred_mixed <- predict.mnl(m3, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed_plot <- tableGrob(pred_mixed_table)
grid.arrange(pred_mixed_plot)
pred_mixed <- predict.mnl(m2.mixed2, new.data)
m2.mixed2 <- update(m2.mixed, correlation = TRUE)
summary(m2.mixed2)
# To get a better sense of the strength of the association among random coefficients,
# we can extract the covariance matrix using "cov.mlogit"
# and then convert it to a correlation matrix using "cov2cor" from base R.
cov2cor(cov.mlogit(m2.mixed2))
# Calculate correlation matrix
cor_mat <- cov2cor(cov.mlogit(m2.mixed2))
library(ggplot2)
library(reshape2)
cor_mat <- cov2cor(cov.mlogit(m2.mixed2))
cor_long <- melt(cor_mat)
ggplot(cor_long, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1, 1)) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "", y = "", fill = "Correlation")
# We can also obtain the standard errors of the correlations among random effects,
# and hence perform significance test
summary(vcov(m2.mixed2, what = "rpar", type = "cor"))
# We may restrict the correlation to only random parameters with significant association
m2.mixed3 <- update(m2.mixed2, correlation = c("cost20", "cost25"))
# The significant presence of random coefficients and their correlation
# can be further investigated using the ML tests, such as the ML ratio test
lrtest(m2, m2.mixed) #Fixed effects vs. uncorrelated random effects
lrtest(m2.mixed, m2.mixed2) #Uncorrelated random effects vs. all correlated random effects
lrtest(m2.mixed3, m2.mixed2)
library(MASS)
predict.mixed.mnl <- function(model, data, nresp=1000) {
# Function for predicting shares from a mixed MNL model
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
#       predict shares. Same format at the data used to estimate model.
# Note that this code assumes all model parameters are random
data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
coef.Sigma <- cov.mlogit(model)
coef.mu <- model$coef[1:dim(coef.Sigma)[1]]
draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
for (i in 1:nresp) {
utility <- data.model%*%draws[i,]
share = exp(utility)/sum(exp(utility))
shares[i,] <- share
}
cbind(colMeans(shares), data)
}
set.seed(1111)
predict.mixed.mnl(m2.mixed2, data=new.data)
predict.mixed.mnl(m2.mixed2, data=new.data_new) # prediciton with our new product
#Table Before
pred_mixed <- predict.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
#Table Before
pred_mixed <- predict.mnl(m2.mixed2, new.data)
#Table Before
pred_mixed <- predict.mixed.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed
#Table Before
pred_mixed <- predict.mixed.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
colnames(pred_mixed_table)[1] <- "share"
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed_plot <- tableGrob(pred_mixed_table)
grid.arrange(pred_mixed_plot)
predict.mixed.mnl(m2.mixed2, data=new.data)
predict.mixed.mnl(m2.mixed2, data=new.data_new) # prediciton with our new product
grid.arrange(pred_mixed_plot_new)
pred_mixed <- predict.mixed.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
colnames(pred_mixed_table)[1] <- "share"
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed_plot <- tableGrob(pred_mixed_table)
grid.arrange(pred_mixed_plot)
pred <- predict.mnl(m3, new.data)
pred_table <- as.data.frame(pred, row.names = NULL)
pred_table$share <- round(pred_table$share, 4)
pred_plot <- tableGrob(pred_table)
grid.arrange(pred_plot)
# We then pass these designs to predict.mnl() to determine what customers
# would choose if they had to pick among these six choice_data alternatives:
predict.mnl(m3, new.data) # using m3 specification
predict.mixed.mnl(m2.mixed2, data=new.data)
#Table Before
pred_mixed <- predict.mixed.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
colnames(pred_mixed_table)[1] <- "share"
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed_plot <- tableGrob(pred_mixed_table)
grid.arrange(pred_mixed_plot)
predict.mixed.mnl(m2.mixed2, data=new.data_new) # prediciton with our new product
set.seed(1111)
predict.mixed.mnl(m2.mixed2, data=new.data)
predict.mixed.mnl(m2.mixed2, data=new.data_new) # prediciton with our new product
#Table Before
pred_mixed <- predict.mixed.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
colnames(pred_mixed_table)[1] <- "share"
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed_plot <- tableGrob(pred_mixed_table)
grid.arrange(pred_mixed_plot)
pred_mixed <- predict.mixed.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
colnames(pred_mixed_table)[1] <- "share"
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed_plot <- tableGrob(pred_mixed_table)
grid.arrange(pred_mixed_plot)
#Table Before
set.seed(1111)
pred_mixed <- predict.mixed.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
colnames(pred_mixed_table)[1] <- "share"
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed_plot <- tableGrob(pred_mixed_table)
grid.arrange(pred_mixed_plot)
set.seed(1111)
pred_mixed_new <- predict.mixed.mnl(m2.mixed2, new.data_new)
pred_mixed_table_new <- as.data.frame(pred_mixed_new, row.names = NULL)
colnames(pred_mixed_table_new)[1] <- "share"
pred_mixed_table_new$share <- round(pred_mixed_table_new$share, 4)
pred_mixed_plot_new <- tableGrob(pred_mixed_table_new)
grid.arrange(pred_mixed_plot_new)
#Table Before
set.seed(1111)
pred_mixed <- predict.mixed.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
colnames(pred_mixed_table)[1] <- "share"
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed_plot <- tableGrob(pred_mixed_table)
grid.arrange(pred_mixed_plot)
predict.mixed.mnl(m2.mixed2, data=new.data_new) # prediciton with our new product
#Table Before
set.seed(1111)
predict.mixed.mnl(m2.mixed2, data=new.data_new) # prediciton with our new product
predict.mixed.mnl <- function(model, data, nresp=1000, seed = 1111) {
# Function for predicting shares from a mixed MNL model
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
#       predict shares. Same format at the data used to estimate model.
# Note that this code assumes all model parameters are random
set.seed(seed)
data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
coef.Sigma <- cov.mlogit(model)
coef.mu <- model$coef[1:dim(coef.Sigma)[1]]
draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
for (i in 1:nresp) {
utility <- data.model%*%draws[i,]
share = exp(utility)/sum(exp(utility))
shares[i,] <- share
}
cbind(colMeans(shares), data)
}
predict.mixed.mnl(m2.mixed2, data=new.data)
predict.mixed.mnl(m2.mixed2, data=new.data_new) # prediciton with our new product
#Table After
pred_mixed_new <- predict.mixed.mnl(m2.mixed2, new.data_new)
pred_mixed <- predict.mixed.mnl(m2.mixed2, new.data)
pred_mixed_table <- as.data.frame(pred_mixed, row.names = NULL)
colnames(pred_mixed_table)[1] <- "share"
pred_mixed_table$share <- round(pred_mixed_table$share, 4)
pred_mixed_plot <- tableGrob(pred_mixed_table)
grid.arrange(pred_mixed_plot)
pred_mixed_new <- predict.mixed.mnl(m2.mixed2, new.data_new)
pred_mixed_table_new <- as.data.frame(pred_mixed_new, row.names = NULL)
colnames(pred_mixed_table_new)[1] <- "share"
pred_mixed_table_new$share <- round(pred_mixed_table_new$share, 4)
pred_mixed_plot_new <- tableGrob(pred_mixed_table_new)
grid.arrange(pred_mixed_plot_new)
